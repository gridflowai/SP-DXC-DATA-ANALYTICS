{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8918b915-2e34-48a4-9ef0-adc33013acdf",
   "metadata": {},
   "source": [
    "#### Stemming words\n",
    "\n",
    "The idea of stemming is a sort of normalizing method. Many variations of words carry the same meaning, other than when tense is involved.\n",
    "\n",
    "The reason why we stem is to shorten the lookup, and normalize sentences.\n",
    "\n",
    "Consider:\n",
    "\n",
    "I was taking a ride in the car.\n",
    "I was riding in the car.\n",
    "\n",
    "One of the most popular stemming algorithms is the __Porter stemmer__, which has been around since 1979."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d8553c-9ed8-4378-9ef1-a0756323cf93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b404c386-ec87-4102-b72d-dc2e0395e607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "porter   = PorterStemmer()\n",
    "lancaster= LancasterStemmer()\n",
    "sno      = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991c97bb-5381-4a56-bebf-937bd53b5e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Porter Stemmer       lancaster Stemmer    Snowball Stemmer    \n",
      "cave                 cave                 cav                  cave                \n",
      "caver                caver                cav                  caver               \n",
      "caved                cave                 cav                  cave                \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"cave\", \"caver\", \"caved\"]\n",
    "\n",
    "print(\"{0:20} {1:20} {2:20} {3:20}\".format(\"Word\",\"Porter Stemmer\", \"lancaster Stemmer\", \"Snowball Stemmer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20} {1:20} {2:20} {3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ceeea6-e1ab-4b8e-bda5-b29feb36f0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Porter Stemmer       lancaster Stemmer    Snowball Stemmer    \n",
      "run                  run                  run                  run                 \n",
      "ran                  ran                  ran                  ran                 \n",
      "runner               runner               run                  runner              \n",
      "running              run                  run                  run                 \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"run\", \"ran\", \"runner\", \"running\"]\n",
    "\n",
    "print(\"{0:20} {1:20} {2:20} {3:20}\".format(\"Word\",\"Porter Stemmer\", \"lancaster Stemmer\", \"Snowball Stemmer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20} {1:20} {2:20} {3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93182164-5755-48c5-8abd-2d77539be8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Porter Stemmer       lancaster Stemmer    Snowball Stemmer    \n",
      "cats                 cat                  cat                  cat                 \n",
      "trouble              troubl               troubl               troubl              \n",
      "troubling            troubl               troubl               troubl              \n",
      "troubled             troubl               troubl               troubl              \n",
      "troublesome          troublesom           troublesom           troublesom          \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"cats\", \"trouble\", \"troubling\", \"troubled\", \"troublesome\"]\n",
    "\n",
    "print(\"{0:20} {1:20} {2:20} {3:20}\".format(\"Word\",\"Porter Stemmer\", \"lancaster Stemmer\", \"Snowball Stemmer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20} {1:20} {2:20} {3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc658cc-e9b0-4110-a32a-f25076796bc9",
   "metadata": {},
   "source": [
    "Notice how the PorterStemmer is \n",
    "- giving the root (stem) of the word \"cats\" by simply removing the 's' after cat. This is a suffix added to cat to make it plural. \n",
    "- But if we look at 'trouble', 'troubling' and 'troubled' they are stemmed to 'trouble' because **PorterStemmer algorithm does not follow linguistics rather a set of 05 rules for different cases that are applied in phases (step by step) to generate stems**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bef069-cce9-4870-b7d8-b963b208a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Porter Stemmer       lancaster Stemmer    Snowball Stemmer    \n",
      "argue                argu                 argu                 argu                \n",
      "argued               argu                 argu                 argu                \n",
      "argues               argu                 argu                 argu                \n",
      "arguing              argu                 argu                 argu                \n",
      "argus                argu                 arg                  argus               \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"argue\", \"argued\", \"argues\", \"arguing\", \"argus\"]\n",
    "\n",
    "print(\"{0:20} {1:20} {2:20} {3:20}\".format(\"Word\",\"Porter Stemmer\", \"lancaster Stemmer\", \"Snowball Stemmer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20} {1:20} {2:20} {3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541b487-df09-4a6e-9577-38f052b9355f",
   "metadata": {},
   "source": [
    "### lemmatization\n",
    "\n",
    "Lemmatization is the process of converting a word to its base form. \n",
    "\n",
    "The difference between stemming and lemmatization is, \n",
    "\n",
    "> lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors.\n",
    "\n",
    "For example, lemmatization would correctly identify the base form of ‘caring’ to ‘care’, whereas, stemming would cutoff the ‘ing’ part and convert it to car.\n",
    "\n",
    "    ‘Caring’ -> Lemmatization -> ‘Care’\n",
    "    ‘Caring’ -> Stemming -> ‘Car’\n",
    "    \n",
    "ways to lemmatize:-\n",
    "\n",
    "    Wordnet Lemmatizer\n",
    "    Spacy Lemmatizer\n",
    "    TextBlob\n",
    "    CLiPS Pattern\n",
    "    Stanford CoreNLP\n",
    "    Gensim Lemmatizer\n",
    "    TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972396c7-f830-4504-b6a5-d9143e462648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb887fa-704a-4425-8328-8dc6748bc94b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 WordNetLemmatizer   \n",
      "friend               friend               \n",
      "friendship           friendship           \n",
      "friends              friend               \n",
      "friendships          friendship           \n",
      "stabilize            stabilize            \n",
      "destabilize          destabilize          \n",
      "misunderstanding     misunderstanding     \n",
      "railroad             railroad             \n",
      "moonlight            moonlight            \n",
      "football             football             \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabilize\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\n",
    "\n",
    "print(\"{0:20} {1:20}\".format(\"Word\",\"WordNetLemmatizer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20} {1:20} \".format(word, lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dffe499-faed-4447-9751-db9c95053ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat\n",
      "are\n",
      "foot\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize Single Word\n",
    "print(lemmatizer.lemmatize(\"bats\"))\n",
    "\n",
    "print(lemmatizer.lemmatize(\"are\"))\n",
    "\n",
    "print(lemmatizer.lemmatize(\"feet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72cf1874-aed0-4d9e-b0a3-c77d8236a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "# Define the sentence to be lemmatized\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "\n",
    "# Tokenize: Split the sentence into words\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b371455d-6247-41c8-a7fd-b014d4fc226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> The\n",
      "striped --> striped\n",
      "bats --> bat\n",
      "are --> are\n",
      "hanging --> hanging\n",
      "on --> on\n",
      "their --> their\n",
      "feet --> foot\n",
      "for --> for\n",
      "best --> best\n"
     ]
    }
   ],
   "source": [
    "for w in word_list:\n",
    "    print(w, '-->', lemmatizer.lemmatize(w) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b94c4-f859-4dbf-8332-29c4f7bc824d",
   "metadata": {},
   "source": [
    "Notice it didn’t do a good job. Because, ‘are’ is not converted to ‘be’ and ‘hanging’ is not converted to ‘hang’ as expected. \n",
    "\n",
    "This can be corrected if we provide the correct ‘part-of-speech’ tag (POS tag) as the second argument to lemmatize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e4500b-7033-477c-b341-d7c26dd567a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n",
      "stripe\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"stripes\", 'v')) \n",
    "print(lemmatizer.lemmatize(\"stripes\", 'n'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2bd0f-b495-48ea-b5f7-9ca909f102df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e12a9f-c5b1-4cc1-8bde-6cb34b3ece0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfba5e0-cd0d-480c-901b-645c801552fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
