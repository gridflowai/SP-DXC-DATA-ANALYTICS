{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d51800b-002c-4066-a190-16644db1e80d",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "#### SentencePiece\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55918fa3-0169-423b-bb5b-eaed586c3f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8932c0f2-2b75-4138-ae98-f71ca2609428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/google/sentencepiece/master/data/botchan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fab930d-25eb-46e8-a2e0-47b444b581f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location = r'D:\\\\AI-DATASETS\\\\01-MISC\\\\botchan.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb33b73-7d23-4185-bf87-89039236763a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233cd376-a1fb-4bca-b298-069738e255b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "spm.SentencePieceTrainer.train('--input=D:\\\\AI-DATASETS\\\\01-MISC\\\\botchan.txt --model_prefix=m --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a71b58d-57fa-49b8-963f-6d49e9b8cc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb9db3c-0c8b-480c-ace2-017f38f3c348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁This', '▁is', '▁a', '▁t', 'est']\n",
      "[208, 31, 9, 434, 601]\n"
     ]
    }
   ],
   "source": [
    "# encode: text => id\n",
    "print(sp.encode_as_pieces('This is a test'))\n",
    "print(sp.encode_as_ids('This is a test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c02e53-7ede-4f55-9e92-e6c71a21e908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n",
      "This is a test\n"
     ]
    }
   ],
   "source": [
    "# decode: id => text\n",
    "print(sp.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n",
    "print(sp.decode_ids([208, 31, 9, 434, 601]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9987e59-940c-413a-b595-2f0b49d6a48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# returns vocab size\n",
    "print(sp.get_piece_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbacac1e-85fc-4544-b580-eeadde89c14e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "# id <=> piece conversion\n",
    "print(sp.id_to_piece(209))\n",
    "print(sp.piece_to_id('▁This'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c9e9e0-3aee-4164-8c79-bf11e494e76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# returns 0 for unknown tokens (we can change the id for UNK)\n",
    "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "696932f1-3b3d-4d5f-ac36-7d5edb6d6be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> False\n",
      "<s> True\n",
      "</s> True\n"
     ]
    }
   ],
   "source": [
    "# <unk>, <s>, </s> are defined by default. Their ids are (0, 1, 2)\n",
    "# <s> and </s> are defined as 'control' symbol.\n",
    "for id in range(3):\n",
    "  print(sp.id_to_piece(id), sp.is_control(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83ce21-5057-4f16-9142-16eaac9fd81d",
   "metadata": {},
   "source": [
    "#### Loads model from byte stream\n",
    "Sentencepiece's model file is just a serialized protocol buffer. \n",
    "\n",
    "We can instantiate sentencepiece processor from byte object with `load_from_serialized_proto` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c3d3aa1-69e0-4bef-b3ff-056579212887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0169ec7-46a4-4c36-9aee-942fabc90883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assumes that m.model is stored in non-Posix file system.\n",
    "serialized_model_proto = tf.io.gfile.GFile('m.model', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba43f028-e094-423f-a49e-d8ec6b6051eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load_from_serialized_proto(serialized_model_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b5ba63e-6352-46da-b779-b4a6acc1b0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁this', '▁is', '▁a', '▁t', 'est']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode_as_pieces('this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9b7591-fee2-4c4c-a3fc-b24eded27c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁my', '▁name', '▁is', '▁B', 'h', 'up', 'en', '▁and', '▁I', '▁like', '▁to', '▁teach', '▁D', 'at', 'a', '▁S', 'c', 'i', 'ence']\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_pieces('my name is Bhupen and I like to teach Data Science'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e7a5f-1a0a-40ca-acbd-f6d5b0a04ac6",
   "metadata": {},
   "source": [
    "#### BPE (Byte pair encoding) model\n",
    "- `Sentencepiece` supports BPE (byte-pair-encoding) for subword segmentation with `--model_type=bpe` flag. \n",
    "- We do not find empirical differences in translation quality between `BPE` and `unigram` model, but unigram model can perform sampling and n-best segmentation. See subword regularization paper [kudo18] for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f09ec28-fb9b-4704-8476-b238e2462c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train('--input=D:\\\\AI-DATASETS\\\\01-MISC\\\\botchan.txt --model_prefix=m_bpe --model_type=bpe --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e6505bb-00d1-47b3-9cab-a176951d3113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp_bpe = spm.SentencePieceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0d27062-b166-495f-bf4d-3085007b5fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_bpe.load('m_bpe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f951428d-da55-48ba-9d29-61295219b5be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** BPE ***\n",
      "['▁this', 'is', 'at', 'est', 'he', 'llow', 'or', 'ld']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print('*** BPE ***')\n",
    "print(sp_bpe.encode_as_pieces('thisisatesthelloworld'))\n",
    "print(sp_bpe.nbest_encode_as_pieces('hello world', 5))  # returns an empty list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf60c69-4d9a-4720-82f4-43eafdda4172",
   "metadata": {},
   "source": [
    "**using unigram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f5c0abf-c5b9-4ff7-90d2-034c0f5c71f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train('--input=D:\\\\AI-DATASETS\\\\01-MISC\\\\botchan.txt --model_prefix=m_unigram --model_type=unigram --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57f98c29-f2e0-4714-b510-dba8fcc1a210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Unigram ***\n",
      "['▁this', 'is', 'ate', 's', 'the', 'll', 'ow', 'or', 'l', 'd']\n",
      "\n",
      "[['▁this', 'is', 'ate', 's', 'the', 'll', 'ow', 'or', 'l', 'd'], ['▁this', 'i', 's', 'ate', 's', 'the', 'll', 'ow', 'or', 'l', 'd'], ['▁this', 'is', 'at', 'es', 'the', 'll', 'ow', 'or', 'l', 'd'], ['▁this', 'is', 'ate', 'st', 'he', 'll', 'ow', 'or', 'l', 'd'], ['▁this', 'is', 'at', 'est', 'he', 'll', 'ow', 'or', 'l', 'd']]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['▁he', 'll', 'o', '▁world'],\n",
       " ['▁he', 'l', 'l', 'o', '▁world'],\n",
       " ['▁', 'he', 'll', 'o', '▁world'],\n",
       " ['▁', 'h', 'e', 'll', 'o', '▁world'],\n",
       " ['▁he', 'll', 'o', '▁wor', 'l', 'd']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_unigram = spm.SentencePieceProcessor()\n",
    "sp_unigram.load('m_unigram.model')\n",
    "\n",
    "print('*** Unigram ***')\n",
    "print(sp_unigram.encode_as_pieces('thisisatesthelloworld'))\n",
    "print()\n",
    "print(sp_unigram.nbest_encode_as_pieces('thisisatesthelloworld', 5))\n",
    "print()\n",
    "sp_unigram.nbest_encode_as_pieces('hello world', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe56bc-4090-48a4-a16b-4dc582f8f186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742eb97e-20da-46b8-91ca-e8643c08951c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fa850-5505-4a5c-8a65-4903f910cbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fd48b-d4e0-453b-8b08-408ff2749ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61536254-8695-405e-b7c6-850e68eec46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_substrings(word, min_length=1, max_length=3):\n",
    "    \"\"\"\n",
    "    Get all unique substrings of lengths 1 to 3 from a given word.\n",
    "    \"\"\"\n",
    "    substrings = set()\n",
    "    for length in range(min_length, min(max_length + 1, len(word) + 1)):\n",
    "        for start in range(len(word) - length + 1):\n",
    "            substring = word[start:start + length]\n",
    "            substrings.add(substring)\n",
    "    return substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01736a5-8004-4247-9bd4-ec70eca7d8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given list of words\n",
    "word_list = [\"hug\", \"pug\", \"pun\", \"bun\", \"hugs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e3a864-eb93-4531-932f-f38a347330d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all unique substrings of lengths 1 to 3 from the 3-letter words\n",
    "all_substrings = set()\n",
    "for word in word_list:\n",
    "    substrings = get_substrings(word)\n",
    "    all_substrings.update(substrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ee4faf-dfc2-4e10-9976-0c11d9dcbdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Unique Substrings (Lengths 1 to 3): {'s', 'bu', 'pun', 'pug', 'p', 'g', 'ugs', 'pu', 'bun', 'h', 'u', 'gs', 'un', 'n', 'hug', 'b', 'hu', 'ug'}\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(\"All Unique Substrings (Lengths 1 to 3):\", all_substrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae4e06-0740-48d7-99d6-75a91e7e5ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
