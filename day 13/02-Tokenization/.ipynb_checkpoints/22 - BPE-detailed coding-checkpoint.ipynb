{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c7f635-8fa0-4d97-999d-afd72bec7b0c",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "#### Token Learning Example\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158e98b0-1b21-4de4-bec3-e1dc26e87a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70fa251c-7686-422f-8f1e-87beb08ac473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracts vocab with frequency\n",
    "# {'A f t e r </w>': 1,\n",
    "#  'e a c h </w>': 1,\n",
    "#  'm e r g e , </w>': 1,\n",
    "#  't h e r e </w>': 1,\n",
    "#  'c o u l d </w>': 1,\n",
    "\n",
    "def get_vocab(filename):\n",
    "    \n",
    "    vocab = collections.defaultdict(int)\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as fhand:\n",
    "        for line in fhand:\n",
    "            words = line.strip().split()\n",
    "            \n",
    "            for word in words:\n",
    "                vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32276e7c-170f-4060-8bfe-2171e0a245e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'bpe-example.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe67fb55-b411-441d-8e48-b6f237078c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'A f t e r </w>': 1,\n",
       "             'e a c h </w>': 1,\n",
       "             'm e r g e , </w>': 1,\n",
       "             't h e r e </w>': 1,\n",
       "             'c o u l d </w>': 1,\n",
       "             'b e </w>': 1,\n",
       "             't h r e e </w>': 1,\n",
       "             's c e n a r i o s , </w>': 1,\n",
       "             't h e </w>': 4,\n",
       "             'n u m b e r </w>': 3,\n",
       "             'o f </w>': 3,\n",
       "             't o k e n s </w>': 2,\n",
       "             'd e c r e a s e s </w>': 1,\n",
       "             'b y </w>': 2,\n",
       "             'o n e , </w>': 1,\n",
       "             'r e m a i n s </w>': 1,\n",
       "             's a m e </w>': 1,\n",
       "             'o r </w>': 1,\n",
       "             'i n c r e a s e s </w>': 2,\n",
       "             'o n e . </w>': 1,\n",
       "             'B u t </w>': 1,\n",
       "             'i n </w>': 1,\n",
       "             'p r a c t i c e , </w>': 1,\n",
       "             'a s </w>': 1,\n",
       "             'm e r g e s </w>': 1,\n",
       "             'i n c r e a s e s , </w>': 1,\n",
       "             'u s u a l l y </w>': 1,\n",
       "             'f i r s t </w>': 1,\n",
       "             't h e n </w>': 1,\n",
       "             'd e c r e a s e s . </w>': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c75421-d38f-4562-a4f4-d476b773ef41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c125dfc-89ef-43a8-9849-ccb0c51c13e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0178d13-bcf6-4e0a-a320-c4f978c15dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get tokens\n",
    "def get_tokens(vocab):\n",
    "    tokens = collections.defaultdict(int)\n",
    "    \n",
    "    for word, freq in vocab.items():\n",
    "        word_tokens = word.split()\n",
    "        \n",
    "        for token in word_tokens:\n",
    "            tokens[token] += freq\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3e5405-bf92-4f7b-a91b-6b36bb0b5822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = r'D:\\AI-DATASETS\\01-MISC\\pg.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3114ce34-6e49-4056-a4b7-cd14dccea52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = get_vocab(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdcabb45-253d-4b09-b35b-61bf611e2ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Before BPE\n",
      "Tokens: defaultdict(<class 'int'>, {'T': 1607, 'h': 26103, 'e': 59190, '</w>': 101849, 'P': 780, 'r': 29562, 'o': 35007, 'j': 858, 'c': 13900, 't': 44238, 'G': 300, 'u': 13723, 'n': 32498, 'b': 7426, 'g': 8752, 'B': 1162, 'k': 2732, 'f': 10463, 'A': 1379, 'l': 20619, 'd': 17581, 'M': 1204, 'i': 31414, 's': 28311, 'a': 36695, 'y': 8828, 'w': 8155, 'U': 178, 'S': 865, 'm': 9751, 'p': 8030, 'v': 4878, '.': 4061, 'Y': 250, ',': 8065, '-': 1063, 'L': 426, 'I': 1428, ':': 201, 'J': 78, 'V': 102, 'E': 895, 'R': 369, '6': 73, '2': 160, '0': 402, '5': 124, '[': 32, '#': 1, '1': 291, '4': 99, '7': 60, ']': 32, 'D': 322, 'C': 862, 'K': 41, 'O': 510, '/': 31, '*': 22, 'F': 419, 'H': 688, 'N': 793, '\"': 4064, '!': 1214, 'W': 576, '3': 104, \"'\": 1236, 'Q': 33, 'X': 49, 'Z': 10, '?': 651, '8': 73, '9': 36, '_': 1426, 'à': 3, 'x': 937, 'z': 364, '°': 41, 'q': 575, ';': 561, '(': 53, ')': 53, '{': 23, '}': 16, 'è': 2, 'é': 14, '+': 2, '=': 3, 'ö': 2, 'ê': 5, 'â': 1, 'ô': 1, 'Æ': 3, 'æ': 2, '—': 2, '™': 57, '“': 11, '”': 11, '•': 4, '%': 1, '‘': 1, '’': 6, '$': 2})\n",
      "Number of tokens: 103\n"
     ]
    }
   ],
   "source": [
    "print('Tokens Before BPE')\n",
    "tokens = get_tokens(vocab)\n",
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0432dba5-7678-4306-afa0-f38b10d26942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Best pair: ('e', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'T': 1607, 'h': 26103, 'e</w>': 17758, 'P': 780, 'r': 29562, 'o': 35007, 'j': 858, 'e': 41432, 'c': 13900, 't': 44238, '</w>': 84091, 'G': 300, 'u': 13723, 'n': 32498, 'b': 7426, 'g': 8752, 'B': 1162, 'k': 2732, 'f': 10463, 'A': 1379, 'l': 20619, 'd': 17581, 'M': 1204, 'i': 31414, 's': 28311, 'a': 36695, 'y': 8828, 'w': 8155, 'U': 178, 'S': 865, 'm': 9751, 'p': 8030, 'v': 4878, '.': 4061, 'Y': 250, ',': 8065, '-': 1063, 'L': 426, 'I': 1428, ':': 201, 'J': 78, 'V': 102, 'E': 895, 'R': 369, '6': 73, '2': 160, '0': 402, '5': 124, '[': 32, '#': 1, '1': 291, '4': 99, '7': 60, ']': 32, 'D': 322, 'C': 862, 'K': 41, 'O': 510, '/': 31, '*': 22, 'F': 419, 'H': 688, 'N': 793, '\"': 4064, '!': 1214, 'W': 576, '3': 104, \"'\": 1236, 'Q': 33, 'X': 49, 'Z': 10, '?': 651, '8': 73, '9': 36, '_': 1426, 'à': 3, 'x': 937, 'z': 364, '°': 41, 'q': 575, ';': 561, '(': 53, ')': 53, '{': 23, '}': 16, 'è': 2, 'é': 14, '+': 2, '=': 3, 'ö': 2, 'ê': 5, 'â': 1, 'ô': 1, 'Æ': 3, 'æ': 2, '—': 2, '™': 57, '“': 11, '”': 11, '•': 4, '%': 1, '‘': 1, '’': 6, '$': 2})\n",
      "Number of tokens: 104\n",
      "==========\n",
      "Iter: 1\n",
      "Best pair: ('t', 'h')\n",
      "Tokens: defaultdict(<class 'int'>, {'T': 1607, 'h': 12062, 'e</w>': 17758, 'P': 780, 'r': 29562, 'o': 35007, 'j': 858, 'e': 41432, 'c': 13900, 't': 30197, '</w>': 84091, 'G': 300, 'u': 13723, 'n': 32498, 'b': 7426, 'g': 8752, 'B': 1162, 'k': 2732, 'f': 10463, 'A': 1379, 'l': 20619, 'd': 17581, 'th': 14041, 'M': 1204, 'i': 31414, 's': 28311, 'a': 36695, 'y': 8828, 'w': 8155, 'U': 178, 'S': 865, 'm': 9751, 'p': 8030, 'v': 4878, '.': 4061, 'Y': 250, ',': 8065, '-': 1063, 'L': 426, 'I': 1428, ':': 201, 'J': 78, 'V': 102, 'E': 895, 'R': 369, '6': 73, '2': 160, '0': 402, '5': 124, '[': 32, '#': 1, '1': 291, '4': 99, '7': 60, ']': 32, 'D': 322, 'C': 862, 'K': 41, 'O': 510, '/': 31, '*': 22, 'F': 419, 'H': 688, 'N': 793, '\"': 4064, '!': 1214, 'W': 576, '3': 104, \"'\": 1236, 'Q': 33, 'X': 49, 'Z': 10, '?': 651, '8': 73, '9': 36, '_': 1426, 'à': 3, 'x': 937, 'z': 364, '°': 41, 'q': 575, ';': 561, '(': 53, ')': 53, '{': 23, '}': 16, 'è': 2, 'é': 14, '+': 2, '=': 3, 'ö': 2, 'ê': 5, 'â': 1, 'ô': 1, 'Æ': 3, 'æ': 2, '—': 2, '™': 57, '“': 11, '”': 11, '•': 4, '%': 1, '‘': 1, '’': 6, '$': 2})\n",
      "Number of tokens: 105\n",
      "==========\n",
      "Iter: 2\n",
      "Best pair: ('t', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'T': 1607, 'h': 12062, 'e</w>': 17758, 'P': 780, 'r': 29562, 'o': 35007, 'j': 858, 'e': 41432, 'c': 13900, 't</w>': 9280, 'G': 300, 'u': 13723, 't': 20917, 'n': 32498, 'b': 7426, 'g': 8752, '</w>': 74811, 'B': 1162, 'k': 2732, 'f': 10463, 'A': 1379, 'l': 20619, 'd': 17581, 'th': 14041, 'M': 1204, 'i': 31414, 's': 28311, 'a': 36695, 'y': 8828, 'w': 8155, 'U': 178, 'S': 865, 'm': 9751, 'p': 8030, 'v': 4878, '.': 4061, 'Y': 250, ',': 8065, '-': 1063, 'L': 426, 'I': 1428, ':': 201, 'J': 78, 'V': 102, 'E': 895, 'R': 369, '6': 73, '2': 160, '0': 402, '5': 124, '[': 32, '#': 1, '1': 291, '4': 99, '7': 60, ']': 32, 'D': 322, 'C': 862, 'K': 41, 'O': 510, '/': 31, '*': 22, 'F': 419, 'H': 688, 'N': 793, '\"': 4064, '!': 1214, 'W': 576, '3': 104, \"'\": 1236, 'Q': 33, 'X': 49, 'Z': 10, '?': 651, '8': 73, '9': 36, '_': 1426, 'à': 3, 'x': 937, 'z': 364, '°': 41, 'q': 575, ';': 561, '(': 53, ')': 53, '{': 23, '}': 16, 'è': 2, 'é': 14, '+': 2, '=': 3, 'ö': 2, 'ê': 5, 'â': 1, 'ô': 1, 'Æ': 3, 'æ': 2, '—': 2, '™': 57, '“': 11, '”': 11, '•': 4, '%': 1, '‘': 1, '’': 6, '$': 2})\n",
      "Number of tokens: 106\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "num_merges = 3\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    \n",
    "    if not pairs:\n",
    "        break\n",
    "        \n",
    "    best  = max(pairs, key=pairs.get)\n",
    "    \n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    \n",
    "    print('Iter: {}'.format(i))\n",
    "    print('Best pair: {}'.format(best))\n",
    "    tokens = get_tokens(vocab)\n",
    "    print('Tokens: {}'.format(tokens))\n",
    "    print('Number of tokens: {}'.format(len(tokens)))\n",
    "    print('==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ec711-5df4-46d0-a942-e34a6089f6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
